{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shariahoque/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shariahoque/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shariahoque/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import pandas for data handling\n",
    "import pandas as pd\n",
    "\n",
    "# NLTK is our Natural-Language-Took-Kit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Libraries for helping us with strings\n",
    "import string\n",
    "# Regular Expression Library\n",
    "import re\n",
    "\n",
    "# Import our text vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Import our classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Import some ML helper function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Import our metrics to evaluate our model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# You may need to download these from nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2096, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>site_url</th>\n",
       "      <th>main_img_url</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "      <th>title_without_stopwords</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "      <th>hasImage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
       "      <td>muslims busted they stole millions in govt ben...</td>\n",
       "      <td>print they should pay all the back all the mon...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>muslims busted stole millions govt benefits</td>\n",
       "      <td>print pay back money plus interest entire fami...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reasoning with facts</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>re why did attorney general loretta lynch plea...</td>\n",
       "      <td>why did attorney general loretta lynch plead t...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>attorney general loretta lynch plead fifth</td>\n",
       "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>breaking weiner cooperating with fbi on hillar...</td>\n",
       "      <td>red state  \\nfox news sunday reported this mor...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>breaking weiner cooperating fbi hillary email ...</td>\n",
       "      <td>red state fox news sunday reported morning ant...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
       "      <td>pin drop speech by father of daughter kidnappe...</td>\n",
       "      <td>email kayla mueller was a prisoner and torture...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>pin drop speech father daughter kidnapped kill...</td>\n",
       "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
       "      <td>fantastic trumps  point plan to reform healthc...</td>\n",
       "      <td>email healthcare reform to make america great ...</td>\n",
       "      <td>english</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>fantastic trumps point plan reform healthcare ...</td>\n",
       "      <td>email healthcare reform make america great sin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                      published  \\\n",
       "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
       "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
       "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
       "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
       "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  muslims busted they stole millions in govt ben...   \n",
       "1  re why did attorney general loretta lynch plea...   \n",
       "2  breaking weiner cooperating with fbi on hillar...   \n",
       "3  pin drop speech by father of daughter kidnappe...   \n",
       "4  fantastic trumps  point plan to reform healthc...   \n",
       "\n",
       "                                                text language  \\\n",
       "0  print they should pay all the back all the mon...  english   \n",
       "1  why did attorney general loretta lynch plead t...  english   \n",
       "2  red state  \\nfox news sunday reported this mor...  english   \n",
       "3  email kayla mueller was a prisoner and torture...  english   \n",
       "4  email healthcare reform to make america great ...  english   \n",
       "\n",
       "              site_url                                       main_img_url  \\\n",
       "0  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
       "1  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
       "2  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
       "3  100percentfedup.com  http://100percentfedup.com/wp-content/uploads/...   \n",
       "4  100percentfedup.com  http://100percentfedup.com/wp-content/uploads/...   \n",
       "\n",
       "   type label                            title_without_stopwords  \\\n",
       "0  bias  Real        muslims busted stole millions govt benefits   \n",
       "1  bias  Real         attorney general loretta lynch plead fifth   \n",
       "2  bias  Real  breaking weiner cooperating fbi hillary email ...   \n",
       "3  bias  Real  pin drop speech father daughter kidnapped kill...   \n",
       "4  bias  Real  fantastic trumps point plan reform healthcare ...   \n",
       "\n",
       "                              text_without_stopwords  hasImage  \n",
       "0  print pay back money plus interest entire fami...       1.0  \n",
       "1  attorney general loretta lynch plead fifth bar...       1.0  \n",
       "2  red state fox news sunday reported morning ant...       1.0  \n",
       "3  email kayla mueller prisoner tortured isis cha...       1.0  \n",
       "4  email healthcare reform make america great sin...       1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DataNews/news_articles.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author                      0\n",
      "published                   0\n",
      "title                       0\n",
      "text                       46\n",
      "language                    1\n",
      "site_url                    1\n",
      "main_img_url                1\n",
      "type                        1\n",
      "label                       1\n",
      "title_without_stopwords     2\n",
      "text_without_stopwords     50\n",
      "hasImage                    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#  Inspect \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2045, 12)\n"
     ]
    }
   ],
   "source": [
    "# remove nulls and duplicates\n",
    "# df.dropna(inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# Sanity Check\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                     0\n",
       "published                  0\n",
       "title                      0\n",
       "text                       0\n",
       "language                   0\n",
       "site_url                   0\n",
       "main_img_url               0\n",
       "type                       0\n",
       "label                      0\n",
       "title_without_stopwords    0\n",
       "text_without_stopwords     0\n",
       "hasImage                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2035, 12) after\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "print(df.shape, 'after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fake    1281\n",
       "Real     754\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Find Label balances.\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs            588\n",
       "conspiracy    430\n",
       "bias          389\n",
       "hate          244\n",
       "satire        146\n",
       "state         121\n",
       "junksci       102\n",
       "fake           15\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Find Type balances.\n",
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TEXT: yikes hillary goes off the railspulls a howard dean video\n"
     ]
    }
   ],
   "source": [
    "print(\"Original TEXT:\", df['title'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean TEXT from data: yikes hillary goes railspulls howard dean video\n"
     ]
    }
   ],
   "source": [
    "print(\"Clean TEXT from data:\", df['title_without_stopwords'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"ORIGINAL TEXT:\", df['text'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT: comedian would move spain buy house another country case people threaten leave country dont leave country said live kelly michael weirdly called trump charming interview neve campbell house cards actress would move canada honesty terrifying told huffington post uk barry diller founder iac interactive would move unspecified donald trump doesnt fall ill either move country join resistance told bloomberg lena dunham creator girls would move vancouver know lot people threatening really said matrix awards keeganmichael key star key peele would move canada easy like minutes detroit thats im told tmz chloë sevigny actress guest star portlandia would move nova scotia answered simply nova scotia question would move trump elected al sharpton activist would move donald trump nominee im open support anyone im also reserving ticket wins said press conference natasha lyonne actress orange new black would move mental hospital ill move mental hospital youre like happening said eddie griffin comedian would move africa hes good making money hes ignorantif trump wins im moving africa told dj vlad spike lee director malcolm x would move brooklyn trump wins hell moving back republic brooklyn new york reported vanity fair amber rose model would move unspecified cant even think im moving im cant taking son told us weekly samuel l jackson actor would move south africa hes running popularity cmon let go said view cher would move jupiter elected im moving jupiter tweeted george lopez comedian star george lopez would move mexico wins wont worry immigration well go back told tmz barbra streisand singer would move australia canada facts dont know cant believe im either coming country australia youll let canada told australian journalist michael usher ravensymoné actress host view would move canada confession election republican gets nominated im going move canada entire family already ticket said view note leaving contingent republican candidate winning electionnot trump whoopi goldberg actress host view would move unspecified dont want america maybe time move know said omari hardwick actor power would move italy ill move denver italy donald trump wins presidency im told wrap miley cyrus pop star would move unspecified heart broken piecesi moving president dont say things dont mean wrote instagram post ruth bader ginsburg supreme court justice would move new zealand cant imagine country would donald trump president time us move new zealand told new york times amy schumer comedian actress would move spain need learn speak spanish move spain somewhere beyond comprehension trump crazy told bbc newsnight katie hopkins\n"
     ]
    }
   ],
   "source": [
    "print(\"Clean TEXT from data:\", df['text_without_stopwords'][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words are already removed\n",
    "### Punctuation are already removed\n",
    "### Already in Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I play and start play with player and we all love to play with play'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bring the root of the words\n",
    "def root_words(string):\n",
    "    porter = PorterStemmer()\n",
    "    \n",
    "    #  sentence into a list of words\n",
    "    words = word_tokenize(string)\n",
    "    \n",
    "    valid_words = []\n",
    "\n",
    "    for word in words:\n",
    "        \n",
    "        root_word = porter.stem(word)\n",
    "        \n",
    "        valid_words.append(root_word)\n",
    "        \n",
    "    string = ' '.join(valid_words)\n",
    "\n",
    "    return string \n",
    "\n",
    "sent = 'I played and started playing with players and we all love to play with plays'\n",
    "root_words(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(input_string):\n",
    "    input_string = root_words(input_string)   \n",
    "    return input_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean TEXT from data: muslims busted stole millions govt benefits\n",
      "CLEANDED TEXT: muslim bust stole million govt benefit\n"
     ]
    }
   ],
   "source": [
    "df['title_after'] = df['title_without_stopwords']\n",
    "df['title_after'] = df['title_without_stopwords'].apply(text_pipeline)\n",
    "\n",
    "print(\"Clean TEXT from data:\", df['title_without_stopwords'][0])\n",
    "print(\"CLEANDED TEXT:\", df['title_after'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_after'] = df['text_without_stopwords']\n",
    "df['text_after'] = df['text_without_stopwords'].apply(text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>site_url</th>\n",
       "      <th>main_img_url</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "      <th>title_without_stopwords</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "      <th>hasImage</th>\n",
       "      <th>title_after</th>\n",
       "      <th>text_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>Ann Coulter</td>\n",
       "      <td>2016-10-27T03:05:01.989+03:00</td>\n",
       "      <td>our new country women and minorities hit hardest</td>\n",
       "      <td>wars and rumors of wars russia unveils satan  ...</td>\n",
       "      <td>english</td>\n",
       "      <td>wnd.com</td>\n",
       "      <td>http://www.wnd.com/files/2016/10/danney-willll...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>wikileaks bombshells hillary need know</td>\n",
       "      <td>posted eddie skyhigh potency may scare away cr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wikileak bombshel hillari need know</td>\n",
       "      <td>post eddi skyhigh potenc may scare away crysta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>Larry Elder</td>\n",
       "      <td>2016-10-27T03:05:05.815+03:00</td>\n",
       "      <td>trump vs clinton a risk vs a disaster</td>\n",
       "      <td>check out hillarythemed haunted house anticlin...</td>\n",
       "      <td>english</td>\n",
       "      <td>wnd.com</td>\n",
       "      <td>http://www.wnd.com/files/2015/10/Hillary-Clint...</td>\n",
       "      <td>bias</td>\n",
       "      <td>Real</td>\n",
       "      <td>fascinated sex</td>\n",
       "      <td>billion even known keeping supposedly deleted ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fascin sex</td>\n",
       "      <td>billion even known keep supposedli delet messa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                      published  \\\n",
       "2044  Ann Coulter  2016-10-27T03:05:01.989+03:00   \n",
       "2045  Larry Elder  2016-10-27T03:05:05.815+03:00   \n",
       "\n",
       "                                                 title  \\\n",
       "2044  our new country women and minorities hit hardest   \n",
       "2045             trump vs clinton a risk vs a disaster   \n",
       "\n",
       "                                                   text language site_url  \\\n",
       "2044  wars and rumors of wars russia unveils satan  ...  english  wnd.com   \n",
       "2045  check out hillarythemed haunted house anticlin...  english  wnd.com   \n",
       "\n",
       "                                           main_img_url  type label  \\\n",
       "2044  http://www.wnd.com/files/2016/10/danney-willll...  bias  Real   \n",
       "2045  http://www.wnd.com/files/2015/10/Hillary-Clint...  bias  Real   \n",
       "\n",
       "                     title_without_stopwords  \\\n",
       "2044  wikileaks bombshells hillary need know   \n",
       "2045                          fascinated sex   \n",
       "\n",
       "                                 text_without_stopwords  hasImage  \\\n",
       "2044  posted eddie skyhigh potency may scare away cr...       1.0   \n",
       "2045  billion even known keeping supposedly deleted ...       0.0   \n",
       "\n",
       "                              title_after  \\\n",
       "2044  wikileak bombshel hillari need know   \n",
       "2045                           fascin sex   \n",
       "\n",
       "                                             text_after  \n",
       "2044  post eddi skyhigh potenc may scare away crysta...  \n",
       "2045  billion even known keep supposedli delet messa...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
